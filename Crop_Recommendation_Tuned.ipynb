{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# !pip install xlsxwriter\n",
    "\n",
    "PATH = 'Crop_recommendation.csv'\n",
    "df = pd.read_csv(PATH)\n",
    "\n",
    "features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\n",
    "target = df['label']\n",
    "labels = df['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arr_max_depth = [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "arr_max_depth2 = ['None', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "arr_criterion = ['gini', 'entropy', 'log_loss']\n",
    "\n",
    "accuracy_max_depth = []\n",
    "accuracy_criterion = []\n",
    "\n",
    "column = 1\n",
    "for max_depth in arr_max_depth:\n",
    "    DecisionTree = DecisionTreeClassifier(max_depth=max_depth, random_state=0)\n",
    "    DecisionTree.fit(Xtrain,Ytrain)\n",
    "    predicted_values = DecisionTree.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_max_depth.append(x*100)\n",
    "    column += 1\n",
    "\n",
    "column = 1\n",
    "for criterion in arr_criterion:\n",
    "    DecisionTree = DecisionTreeClassifier(criterion=criterion, random_state=0)\n",
    "    DecisionTree.fit(Xtrain,Ytrain)\n",
    "    predicted_values = DecisionTree.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_criterion.append(x*100)\n",
    "    column += 1\n",
    "\n",
    "plt.title('max_depth')\n",
    "plt.plot(arr_max_depth2, accuracy_max_depth)\n",
    "plt.show()\n",
    "\n",
    "plt.title('criterion')\n",
    "plt.plot(arr_criterion, accuracy_criterion)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arr_n_estimators = [\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
    "    11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "    21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
    "    31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
    "    41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "    51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
    "    61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
    "    71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
    "    81, 82, 83, 84, 85, 86, 87, 88, 89, 90,\n",
    "    91, 92, 93, 94, 95, 96, 97, 98, 99, 100\n",
    "]\n",
    "\n",
    "arr_max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "arr_max_features = ['sqrt', 'log2', None]\n",
    "arr_max_features2 = ['sqrt', 'log2', 'None']\n",
    "\n",
    "accuracy_n_estimators = []\n",
    "accuracy_max_depth = []\n",
    "accuracy_max_features = []\n",
    "\n",
    "column = 1\n",
    "for n_estimators in arr_n_estimators:\n",
    "    RF = RandomForestClassifier(random_state=0, n_estimators=n_estimators)\n",
    "    RF.fit(Xtrain,Ytrain)\n",
    "    predicted_values = RF.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_n_estimators.append(x*100)\n",
    "    column += 1\n",
    "\n",
    "column = 1\n",
    "for max_depth in arr_max_depth:\n",
    "    RF = RandomForestClassifier(random_state=0, max_depth=max_depth)\n",
    "    RF.fit(Xtrain,Ytrain)\n",
    "    predicted_values = RF.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_max_depth.append(x*100)\n",
    "    column += 1\n",
    "\n",
    "column = 1\n",
    "for max_features in arr_max_features:\n",
    "    RF = RandomForestClassifier(random_state=0, max_features=max_features)\n",
    "    RF.fit(Xtrain,Ytrain)\n",
    "    predicted_values = RF.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_max_features.append(x*100)\n",
    "    column += 1\n",
    "\n",
    "plt.title('n_estimators')\n",
    "plt.plot(arr_n_estimators, accuracy_n_estimators)\n",
    "plt.show()\n",
    "\n",
    "plt.title('max_depth')\n",
    "plt.plot(arr_max_depth, accuracy_max_depth)\n",
    "plt.show()\n",
    "\n",
    "plt.title('max_features')\n",
    "plt.plot(arr_max_features2, accuracy_max_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arr_max_iter = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "arr_activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "arr_solver = ['lbfgs', 'sgd', 'adam']\n",
    "arr_alpha = [0, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005]\n",
    "arr_hidden_layer_sizes = [\n",
    "    (100,), (200,), (300,), (400,), (500,),\n",
    "    (600,), (700,), (800,), (900,), (1000,)\n",
    "]\n",
    "arr_hidden_layer_sizes2 = [\n",
    "    '(100,)', '(200,)', '(300,)', '(400,)', '(500,)',\n",
    "    '(600,)', '(700,)', '(800,)', '(900,)', '(1000,)'\n",
    "]\n",
    "\n",
    "accuracy_max_iter = []\n",
    "accuracy_activation = []\n",
    "accuracy_solver = []\n",
    "accuracy_alpha = []\n",
    "accuracy_hidden_layer_sizes = []\n",
    "\n",
    "column = 1\n",
    "for max_iter in arr_max_iter:\n",
    "    MLP = MLPClassifier(max_iter=max_iter, random_state=0)\n",
    "    MLP.fit(Xtrain, Ytrain)\n",
    "    predicted_values = MLP.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_max_iter.append(x * 100)\n",
    "    column += 1\n",
    "\n",
    "plt.title('max_iter')\n",
    "plt.plot(arr_max_iter, accuracy_max_iter)\n",
    "plt.show()\n",
    "\n",
    "column = 1\n",
    "for activation in arr_activation:\n",
    "    MLP = MLPClassifier(activation=activation, random_state=0)\n",
    "    MLP.fit(Xtrain, Ytrain)\n",
    "    predicted_values = MLP.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_activation.append(x * 100)\n",
    "    column += 1\n",
    "\n",
    "plt.title('activation')\n",
    "plt.plot(arr_activation, accuracy_activation)\n",
    "plt.show()\n",
    "\n",
    "column = 1\n",
    "for solver in arr_solver:\n",
    "    MLP = MLPClassifier(solver=solver, random_state=0)\n",
    "    MLP.fit(Xtrain, Ytrain)\n",
    "    predicted_values = MLP.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_solver.append(x * 100)\n",
    "    column += 1\n",
    "\n",
    "plt.title('solver')\n",
    "plt.plot(arr_solver, accuracy_solver)\n",
    "plt.show()\n",
    "\n",
    "column = 1\n",
    "for alpha in arr_alpha:\n",
    "    MLP = MLPClassifier(alpha=alpha, random_state=0)\n",
    "    MLP.fit(Xtrain, Ytrain)\n",
    "    predicted_values = MLP.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_alpha.append(x * 100)\n",
    "    column += 1\n",
    "\n",
    "plt.title('alpha')\n",
    "plt.plot(arr_alpha, accuracy_alpha)\n",
    "plt.show()\n",
    "\n",
    "column = 1\n",
    "for hidden_layer_sizes in arr_hidden_layer_sizes:\n",
    "    MLP = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, random_state=0)\n",
    "    MLP.fit(Xtrain, Ytrain)\n",
    "    predicted_values = MLP.predict(Xtest)\n",
    "    x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "    accuracy_hidden_layer_sizes.append(x * 100)\n",
    "    column += 1\n",
    "\n",
    "plt.title('hidden_layer_sizes')\n",
    "plt.plot(arr_hidden_layer_sizes2, accuracy_hidden_layer_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=0),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "grid_search.fit(Xtrain, Ytrain)\n",
    "\n",
    "best_MLP = grid_search.best_estimator_\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_MLP.fit(Xtrain, Ytrain)\n",
    "\n",
    "predicted_values = best_MLP.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "\n",
    "print('Decision Tree')\n",
    "print('params: ', best_params)\n",
    "print(\"accuracy: \", x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_features': [\"sqrt\", \"log2\", None],\n",
    "    'max_depth': [\n",
    "        1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
    "        11, 12, 13, 14, 15, 16, 17, 18, 19, 20\n",
    "    ],\n",
    "    'n_estimators': [\n",
    "        1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
    "        11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "        21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
    "        31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
    "        41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
    "        61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
    "        71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
    "        81, 82, 83, 84, 85, 86, 87, 88, 89, 90,\n",
    "        91, 92, 93, 94, 95, 96, 97, 98, 99, 100\n",
    "    ]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=0),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(Xtrain, Ytrain)\n",
    "\n",
    "best_RF = grid_search.best_estimator_\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "test_pred_best = best_RF.predict(Xtest)\n",
    "\n",
    "test_acc_best = accuracy_score(Ytest, test_pred_best)\n",
    "\n",
    "print('Random Forest')\n",
    "print('Param: 'best_params)\n",
    "print(\"Accuracy: \", test_acc_best * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_iter': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005],\n",
    "    'hidden_layer_sizes': [(100,), (200,), (300,), (400,), (500,), (600,), (700,), (800,), (900,), (1000,)]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=MLPClassifier(random_state=0),\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "grid_search.fit(Xtrain, Ytrain)\n",
    "\n",
    "best_MLP = grid_search.best_estimator_\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_MLP.fit(Xtrain, Ytrain)\n",
    "\n",
    "test_pred_best = best_MLP.predict(Xtest)\n",
    "\n",
    "test_acc_best = accuracy_score(Ytest, test_pred_best)\n",
    "\n",
    "print('Multilayer Perceptron')\n",
    "print('params: ', best_params)\n",
    "print(\"Accuracy: \", test_acc_best * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "OldDecisionTree = DecisionTreeClassifier(random_state=0)\n",
    "OldDecisionTree.fit(Xtrain,Ytrain)\n",
    "OldDecisionTreeScore = cross_val_score(OldDecisionTree, features, target,cv=5)\n",
    "OldDecisionTreeScore = sum(OldDecisionTreeScore)/len(OldDecisionTreeScore)\n",
    "\n",
    "NewDecisionTree = DecisionTreeClassifier(random_state=0, max_depth=9, criterion=\"entropy\")\n",
    "NewDecisionTree.fit(Xtrain,Ytrain)\n",
    "NewDecisionTreeScore = cross_val_score(NewDecisionTree, features, target,cv=5)\n",
    "NewDecisionTreeScore = sum(NewDecisionTreeScore)/len(NewDecisionTreeScore)\n",
    "\n",
    "\n",
    "OldRandomForest = RandomForestClassifier(random_state=0)\n",
    "OldRandomForest.fit(Xtrain,Ytrain)\n",
    "OldRandomForestScore = cross_val_score(OldRandomForest, features, target,cv=5)\n",
    "OldRandomForestScore = sum(OldRandomForestScore)/len(OldRandomForestScore)\n",
    "\n",
    "NewRandomForest = RandomForestClassifier(random_state=0, max_depth=15, max_features='sqrt', n_estimators=19)\n",
    "NewRandomForest.fit(Xtrain,Ytrain)\n",
    "NewRandomForestScore = cross_val_score(NewRandomForest, features, target,cv=5)\n",
    "NewRandomForestScore = sum(NewRandomForestScore)/len(NewRandomForestScore)\n",
    "\n",
    "\n",
    "OldMLP = MLPClassifier(random_state=0)\n",
    "OldMLP.fit(Xtrain,Ytrain)\n",
    "OldMLPScore = cross_val_score(OldMLP, features, target,cv=5)\n",
    "OldMLPScore = sum(OldMLPScore)/len(OldMLPScore)\n",
    "\n",
    "NewMLP = MLPClassifier(random_state=0, max_iter=1000, activation='identity', solver='lbfgs', alpha=0, hidden_layer_sizes=300)\n",
    "NewMLP.fit(Xtrain,Ytrain)\n",
    "NewMLPScore = cross_val_score(NewMLP, features, target,cv=5)\n",
    "NewMLPScore = sum(NewMLPScore)/len(NewMLPScore)\n",
    "\n",
    "print('OldDecisionTree: ' + str(round(OldDecisionTreeScore * 100, 2)))\n",
    "print('NewDecisionTree: ' + str(round(NewDecisionTreeScore * 100, 2)))\n",
    "\n",
    "print('OldRandomForest: ' + str(round(OldRandomForestScore * 100, 2)))\n",
    "print('NewRandomForest: ' + str(round(NewRandomForestScore * 100, 2)))\n",
    "\n",
    "print('OldMLP         : ' + str(round(OldMLPScore * 100, 2)))\n",
    "print('NewMLP         : ' + str(round(NewMLPScore * 100, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2022.10.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
